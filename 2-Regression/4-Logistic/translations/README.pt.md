# Regress√£o log√≠stica para prever categorias

![Infogr√°fico log√≠stico vs. regress√£o linear](../images/logistic-linear.png)
> Infographic by [Dasani Madipalli](https://twitter.com/dasani_decoded)
## [Question√°rio pr√©-palestra](https://white-water-09ec41f0f.azurestaticapps.net/quiz/15/)

> ### [Esta li√ß√£o est√° dispon√≠vel em R!](./solution/R/lesson_4-R.ipynb)

## Introdu√ß√£o

Nesta li√ß√£o final sobre Regress√£o, uma das t√©cnicas b√°sicas _classic_ ML, vamos dar uma olhada na Regress√£o Log√≠stica. Usaria esta t√©cnica para descobrir padr√µes para prever categorias bin√°rias. Isto √© chocolate doce ou n√£o? Esta doen√ßa √© contagiosa ou n√£o? Este cliente escolher√° este produto ou n√£o?

Nesta li√ß√£o, aprender√°:
- Uma nova biblioteca para visualiza√ß√£o de dados
- T√©cnicas de regress√£o log√≠stica

‚úÖ aprofundar a sua compreens√£o de trabalhar com este tipo de regress√£o neste [m√≥dulo Aprender](https://docs.microsoft.com/learn/modules/train-evaluate-classification-models?WT.mc_id=academic-15963-cxa)
## Pr√©-requisito

Tendo trabalhado com os dados da ab√≥bora, estamos agora familiarizados o suficiente para perceber que h√° uma categoria bin√°ria com a qual podemos trabalhar:` Cor`.

Vamos construir um modelo de regress√£o log√≠stica para prever que, dadas algumas vari√°veis, _what cor de uma dada ab√≥bora √© prov√°vel que be_ (üéÉ laranja ou üëª branco).

> Porque estamos a falar de classifica√ß√£o bin√°ria num agrupamento de aulas sobre regress√£o? Apenas para conveni√™ncia lingu√≠stica, uma vez que a regress√£o log√≠stica √© [realmente um m√©todo de classifica√ß√£o](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression),embora um linear baseado. Saiba mais sobre outras formas de classificar os dados no pr√≥ximo grupo de aulas.

## Definir a pergunta
Para os nossos prop√≥sitos, vamos expressar isto como um bin√°rio: "Laranja" ou "N√£o Laranja". Existe tamb√©m uma categoria de "listrado" no nosso conjunto de dados, mas h√° poucos casos dele, pelo que n√£o a utilizaremos. Desaparece assim que removemos os valores nulos do conjunto de dados, de qualquer forma.

> üéÉ facto divertido, √†s vezes chamamos ab√≥boras brancas de ab√≥boras "fantasma". N√£o s√£o muito f√°ceis de esculpir, por isso n√£o s√£o t√£o populares como os laranjas, mas s√£o fixes!

## About logistic regression

A regress√£o log√≠stica difere da regress√£o linear, que aprendeu anteriormente, de algumas formas importantes.
### Classifica√ß√£o bin√°ria

A regress√£o log√≠stica n√£o oferece as mesmas caracter√≠sticas que a regress√£o linear. O primeiro oferece uma previs√£o sobre uma categoria bin√°ria ("laranja ou n√£o laranja"),) enquanto esta √© capaz de prever valores cont√≠nuos, por exemplo dada a origem de uma ab√≥bora e a hora da colheita, _how muito o seu pre√ßo ir√° rise_.

![Modelo de classifica√ß√£o de ab√≥bora](../images/pumpkin-classifier.png)
> Infographic by [Dasani Madipalli](https://twitter.com/dasani_decoded)
### Outras classifica√ß√µes

Existem outros tipos de regress√£o log√≠stica, incluindo multin√≥ia e ordin√°ria:
- **Multinomial**, que envolve ter mais de uma categoria - "Laranja, Branco e Listrado".
- **Ordinal**, que envolve categorias ordenadas, √∫teis se quis√©ssemos encomendar os nossos resultados logicamente, como as nossas ab√≥boras que s√£o encomendadas por um n√∫mero finito de tamanhos (mini,sm,med,lg,xl,xxl).

![Regress√£o multinomial vs ordinal](../images/multinomial-ordinal.png)
> Infographic by [Dasani Madipalli](https://twitter.com/dasani_decoded)
### Ainda √© linear

Embora este tipo de Regress√£o seja tudo sobre "previs√µes de categoria", ainda funciona melhor quando h√° uma rela√ß√£o linear clara entre a vari√°vel dependente (cor) e as outras vari√°veis independentes (o resto do conjunto de dados, como o nome e o tamanho da cidade). √â bom ter uma ideia de se h√° alguma linearidade dividindo estas vari√°veis ou n√£o.

### Vari√°veis N√ÉO t√™m que correlacionar
Lembras-te de como a regress√£o linear funcionou melhor com vari√°veis mais correlacionadas? A regress√£o log√≠stica √© o oposto - as vari√°veis n√£o t√™m que se alinhar. Isso funciona para estes dados que t√™m correla√ß√µes um pouco fracas.

### Precisa de muitos dados limpos

A regress√£o log√≠stica dar√° resultados mais precisos se utilizar mais dados; nosso pequeno conjunto de dados n√£o √© o ideal para esta tarefa, por isso tenha isso em mente.

‚úÖ Pense nos tipos de dados que se emprestariam bem √† regress√£o log√≠stica

## Exerc√≠cio - arrumar os dados

Primeiro, limpe um pouco os dados, baixando os valores nulos e selecionando apenas algumas das colunas:

1. Adicione o seguinte c√≥digo:

    ```python
    from sklearn.preprocessing import LabelEncoder
    
    new_columns = ['Color','Origin','Item Size','Variety','City Name','Package']
    
    new_pumpkins = pumpkins.drop([c for c in pumpkins.columns if c not in new_columns], axis=1)
    
    new_pumpkins.dropna(inplace=True)
    
    new_pumpkins = new_pumpkins.apply(LabelEncoder().fit_transform)
    ```

   Pode sempre dar uma olhada no seu novo dataframe:

    ```python
    new_pumpkins.info
    ```

### Visualiza√ß√£o - grelha lado a lado

Por esta altura j√° j√° carregou o [caderno de entrada](./notebook.ipynb) com dados de ab√≥bora mais uma vez e limpou-os de modo a preservar um conjunto de dados contendo algumas vari√°veis, incluindo `Color`. Vamos visualizar o quadro de dados no caderno usando uma biblioteca diferente: [Seaborn](https://seaborn.pydata.org/index.html), que √© constru√≠da em Matplotlib que usamos anteriormente.

Seaborn oferece algumas maneiras limpas de visualizar os seus dados. Por exemplo, pode comparar distribui√ß√µes dos dados por cada ponto numa grelha lado a lado.

1. Crie tal rede atrav√©s da instant√¢nea `PairGrid`, utilizando os nossos dados de ab√≥bora `new_pumpkins`, seguidos de `map()`:

    ```python
    import seaborn as sns
    
    g = sns.PairGrid(new_pumpkins)
    g.map(sns.scatterplot)
    ```

    ![A grid of visualized data](../images/grid.png)

  Ao observar dados lado a lado, pode ver como os dados de Cor se relacionam com as outras colunas.
  
  ‚úÖ Dada esta grelha de dispers√£o, quais s√£o algumas explora√ß√µes interessantes que podes imaginar?

### Use um enredo de enxame
Uma vez que a Cor √© uma categoria bin√°ria (Laranja ou N√£o), chama-se "dados categ√≥ricos" e precisa de "uma abordagem mais [especializada](https://seaborn.pydata.org/tutorial/categorical.html?highlight=bar) √† visualiza√ß√£o". H√° outras formas de visualizar a rela√ß√£o desta categoria com outras vari√°veis.
 
 Voc√™ pode visualizar vari√°veis lado a lado com parcelas seaborn.

1. Experimente um plano de 'enxame' para mostrar a distribui√ß√£o de valores:

    ```python
    sns.swarmplot(x="Color", y="Item Size", data=new_pumpkins)
    ```

    ![Um enxame de dados visualizados](../images/swarm.png)

### Enredo de violino

Um gr√°fico de tipo 'violino' √© √∫til, pois voc√™ pode visualizar facilmente a forma como os dados nas duas categorias s√£o distribu√≠dos. Os gr√°ficos de violino n√£o funcionam t√£o bem com conjuntos de dados menores, pois a distribui√ß√£o √© exibida mais 'suavemente'.

1. Como par√¢metros `x=Color`, `kind="violin"` e chamada `catplot()`:

    ```python
    sns.catplot(x="Color", y="Item Size",
                kind="violin", data=new_pumpkins)
    ```

    ![a violin type chart](images/violin.png)

    ‚úÖ Tente criar este enredo, e outros enredos de Seaborn, usando outras vari√°veis.

Agora que temos uma ideia da rela√ß√£o entre as categorias bin√°rias de cor e o grupo maior de tamanhos, vamos explorar a regress√£o log√≠stica para determinar a cor prov√°vel de uma dada ab√≥bora.

> **üßÆ Mostre-Me A Matem√°tica**
>
> Lembram-se como a regress√£o linear frequentemente usava m√≠nimos quadrados ordin√°rios para chegar a um valor? A regress√£o log√≠stica baseia-se no conceito de "m√°xima verossimilhan√ßa" utilizando [fun√ß√µes sigmoides](https://wikipedia.org/wiki/Sigmoid_function). Uma 'Fun√ß√£o Sigmoide' em uma trama se parece com uma forma 'S'. Ele pega um valor e o mapeia para algum lugar entre 0 e 1. Sua curva tamb√©m √© chamada de "curva log√≠stica". Sua f√≥rmula √© assim:
>
> ![fun√ß√£o log√≠stica](images/sigmoid.png)
>
> onde o ponto m√©dio do sigmoide se encontra no ponto 0 de x, L √© o valor m√°ximo da curva, e k √© a inclina√ß√£o da curva. Se o resultado da fun√ß√£o for maior que 0,5, o r√≥tulo em quest√£o receber√° a classe '1' da escolha bin√°ria. Caso contr√°rio, ser√° classificado como "0".

## Crie o seu modelo

Construir um modelo para encontrar essas classifica√ß√µes bin√°rias √© surpreendentemente simples no Scikit-learn.

1. Selecione as vari√°veis que deseja utilizar no seu modelo de classifica√ß√£o e divida os conjuntos de treino e teste que chamam `train_test_split()`:

    ```python
    from sklearn.model_selection import train_test_split
    
    Selected_features = ['Origin','Item Size','Variety','City Name','Package']
    
    X = new_pumpkins[Selected_features]
    y = new_pumpkins['Color']
    
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
    
    ```

1. Agora voc√™ pode treinar seu modelo, chamando `fit()` com seus dados de treinamento e imprimir o resultado:

    ```python
    from sklearn.model_selection import train_test_split
    from sklearn.metrics import accuracy_score, classification_report 
    from sklearn.linear_model import LogisticRegression
    
    model = LogisticRegression()
    model.fit(X_train, y_train)
    predictions = model.predict(X_test)
    
    print(classification_report(y_test, predictions))
    print('Predicted labels: ', predictions)
    print('Accuracy: ', accuracy_score(y_test, predictions))
    ```

    D√™ uma olhada no placar do seu modelo. N√£o √© t√£o ruim, considerando que voc√™ tem apenas cerca de 1000 linhas de dados:

    ```output
                       precision    recall  f1-score   support
    
               0       0.85      0.95      0.90       166
               1       0.38      0.15      0.22        33
    
        accuracy                           0.82       199
       macro avg       0.62      0.55      0.56       199
    weighted avg       0.77      0.82      0.78       199
    
    Predicted labels:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
     0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
     1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1
     0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1
     0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
     0 0 0 1 0 1 0 0 1 0 0 0 1 0]
    ```

## Melhor compreens√£o atrav√©s de uma matriz de confus√£o

Enquanto voc√™ pode obter um relat√≥rio de placar [termos](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html?highlight=classification_report#sklearn.metrics.classification_report) imprimindo os itens acima, voc√™ pode ser capaz de entender seu modelo mais facilmente usando uma [matriz confus√£o](https://scikit-learn.org/stable/modules/model_evaluation.html#confusion-matrix) para nos ajudar a entender como o modelo est√° se saindo.

> üéì A '[matriz de confus√£o](https://wikipedia.org/wiki/Confusion_matrix)' (ou 'matriz de erros') √© uma tabela que expressa os verdadeiros versus falsos positivos e negativos do seu modelo, avaliando assim a precis√£o das previs√µes.

1. Para usar uma m√©trica de confus√£o, chame`confusion_matrix()`:

    ```python
    from sklearn.metrics import confusion_matrix
    confusion_matrix(y_test, predictions)
    ```

    D√™ uma olhada na matriz de confus√£o do seu modelo:

    ```output
    array([[162,   4],
           [ 33,   0]])
    ```

No Scikit-learn, matrizes de confus√£o Linhas (eixo 0) s√£o r√≥tulos reais e colunas (eixo 1) s√£o r√≥tulos previstos.

|       |   0   |   1   |
| :---: | :---: | :---: |
|   0   |  TN   |  FP   |
|   1   |  FN   |  TP   |

O que est√° acontecendo aqui? Digamos que nosso modelo √© solicitado a classificar ab√≥boras entre duas categorias bin√°rias, categoria 'laranja' e categoria 'n√£o-laranja'.

- Se o seu modelo prev√™ uma ab√≥bora como n√£o laranja e pertence √† categoria 'n√£o-laranja' na realidade chamamos-lhe um verdadeiro negativo, mostrado pelo n√∫mero superior esquerdo.
- Se o seu modelo prev√™ uma ab√≥bora como laranja e pertence √† categoria 'n√£o-laranja' na realidade chamamos-lhe um falso negativo, mostrado pelo n√∫mero inferior esquerdo.
- Se o seu modelo prev√™ uma ab√≥bora como n√£o laranja e pertence √† categoria 'laranja' na realidade chamamos-lhe um falso positivo, mostrado pelo n√∫mero superior direito.
- Se o seu modelo prev√™ uma ab√≥bora como laranja e ela pertence √† categoria 'laranja' na realidade n√≥s chamamos de um verdadeiro positivo, mostrado pelo n√∫mero inferior direito.

Como voc√™s devem ter adivinhado, √© prefer√≠vel ter um n√∫mero maior de verdadeiros positivos e verdadeiros negativos e um n√∫mero menor de falsos positivos e falsos negativos, o que implica que o modelo tem melhor desempenho.

Como a matriz de confus√£o se relaciona com precis√£o e evoca√ß√£o? Lembre-se, o relat√≥rio de classifica√ß√£o impresso acima mostrou precis√£o (0,83) e recupera√ß√£o (0,98).

Precision = tp / (tp + fp) = 162 / (162 + 33) = 0.8307692307692308

Recall = tp / (tp + fn) = 162 / (162 + 4) = 0.9759036144578314

‚úÖ Q: De acordo com a matriz de confus√£o, como foi o modelo? A: Nada mal. h√° um bom n√∫mero de verdadeiros negativos, mas tamb√©m v√°rios falsos negativos.

Vamos revisitar os termos que vimos anteriormente com a ajuda do mapeamento da matriz confus√£o de TP/TN e FP/FN:

üéì precis√£o: TP/(TP + FP) A fra√ß√£o de inst√¢ncias relevantes entre as inst√¢ncias recuperadas (por exemplo, quais r√≥tulos estavam bem rotulados)

üéì Chamada: TP/(TP + FN) A fra√ß√£o de inst√¢ncias relevantes que foram recuperadas, sejam bem rotuladas ou n√£o

üéì f1- score: (2 * precis√£o * recolha)/(precis√£o + recolha) Uma m√©dia ponderada da precis√£o e recolha, sendo a melhor 1 e a pior 0

Suporte üéì: O n√∫mero de ocorr√™ncias de cada r√≥tulo recuperado

üéì precis√£o: (TP + TN)/(TP + TN + FP + FN) A percentagem de r√≥tulos previstos com precis√£o para uma amostra.

üéì M√©d. de Macro: O c√°lculo das m√©tricas m√©dias n√£o ponderadas para cada r√≥tulo, sem levar em conta o desequil√≠brio do r√≥tulo.

üéì M√©dia Ponderada: O c√°lculo das m√©tricas m√©dias para cada label, levando em conta o desequil√≠brio de label ponderando-as pelo suporte (o n√∫mero de inst√¢ncias verdadeiras para cada label).

Consegue pensar qual m√©trica deve observar se quiser que o seu modelo reduza o n√∫mero de falsos negativos?

## Visualizar a curva de ROC deste modelo

Este n√£o √© um mau modelo; sua precis√£o est√° na faixa de 80%, ent√£o idealmente voc√™ poderia us√°-lo para prever a cor de uma ab√≥bora dado um conjunto de vari√°veis.

Vamos fazer mais uma visualiza√ß√£o para ver a chamada pontua√ß√£o 'ROC':

```python
from sklearn.metrics import roc_curve, roc_auc_score

y_scores = model.predict_proba(X_test)
# calculate ROC curve
fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])
sns.lineplot([0, 1], [0, 1])
sns.lineplot(fpr, tpr)
```
Usando Seaborn novamente, plote a [Caracter√≠stica de opera√ß√£o de recep√ß√£o](https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html?highlight=roc) ou ROC do modelo. Curvas ROC s√£o frequentemente usadas para obter uma vis√£o da sa√≠da de um classificador em termos de seus verdadeiros versus falsos positivos. "As curvas ROC geralmente apresentam taxa positiva verdadeira no eixo Y e taxa positiva falsa no eixo X." Assim, a inclina√ß√£o da curva e o espa√ßo entre a linha do ponto m√©dio e a mat√©ria da curva: voc√™ quer uma curva que rapidamente se encaminha para cima e sobre a linha. No nosso caso, h√° falsos positivos para come√ßar, e ent√£o a linha se encaminha para cima e para cima corretamente:

![ROC](./images/ROC.png)

Finalmente, use o Scikit-learn [`roc_auc_score` API](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html?highlight=roc_auc#sklearn.metrics.roc_auc_score) para calcular a '√Årea sob a curva' (AUC) real:

```python
auc = roc_auc_score(y_test,y_scores[:,1])
print(auc)
```
O resultado √© `0,6976998904709748`. Dado que a AUC varia de 0 a 1, voc√™ quer uma grande pontua√ß√£o, uma vez que um modelo que √© 100% correto em suas previs√µes ter√° uma AUC de 1; nesse caso, o modelo √© _muito bom_.

Em li√ß√µes futuras sobre classifica√ß√µes, voc√™ aprender√° a iterar para melhorar as pontua√ß√µes do seu modelo. Mas por enquanto, parab√©ns! Voc√™ completou essas li√ß√µes de regress√£o!

---
## üöÄDesafio

H√° muito mais a desempacotar em rela√ß√£o √† regress√£o log√≠stica! Mas a melhor maneira de aprender √© experimentar. Encontre um conjunto de dados que se preste a esse tipo de an√°lise e construa um modelo com ele. O que voc√™ aprende? dica: tente [Kaggle](https://www.kaggle.com/search?q=logistic+regression+datasets) para obter conjuntos de dados interessantes.

## [Teste p√≥s-aula](https://white-water-09ec41f0f.azurestaticapps.net/quiz/16/)

## An√°lise e autoestudo

Leia as primeiras p√°ginas de [este artigo de Stanford](https://web.stanford.edu/~jurafsky/slp3/5.pdf) sobre alguns usos pr√°ticos para regress√£o log√≠stica. Pense em tarefas que s√£o mais adequadas para um ou outro tipo de tarefas de regress√£o que estudamos at√© agora. O que funcionaria melhor?

## Atribui√ß√£o

[Repetindo esta regress√£o](assignment.md)
