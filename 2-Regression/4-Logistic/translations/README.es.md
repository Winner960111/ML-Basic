# Regresi√≥n log√≠stica para predecir categor√≠as

![Infograf√≠a de regresiones lineal vs log√≠stica](../images/logistic-linear.png)
> Infograf√≠a de [Dasani Madipalli](https://twitter.com/dasani_decoded)

## [Examen previo a la lecci√≥n](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/15?loc=es)

> ### [Esta lecci√≥n se encuentra disponible en R!](../solution/R/lesson_4-R.ipynb)

## Introducci√≥n

En esta lecci√≥n final de Regresi√≥n, una de las t√©cnicas b√°sicas _cl√°sicas_ de aprendizaje autom√°tico, echaremos un vistazo a la regresi√≥n log√≠stica. Usar√°s esta t√©cnica para descubrir patrones que predigan categor√≠as binarias. ¬øEste dulce es un chocolate o no lo es? ¬ø√âsta enfermedad es contagiosa o no?, ¬øEste cliente eligir√° este producto o no? 

En esta lecci√≥n, aprender√°s:

- Una nueva librer√≠a para visualizaci√≥n de datos
- T√©cnicas para regresi√≥n log√≠stica

‚úÖ Profundiza tu entendimiento de trabajo con este tipo de regresi√≥n en este [m√≥dulo de aprendizaje(https://docs.microsoft.com/learn/modules/train-evaluate-classification-models?WT.mc_id=academic-77952-leestott)
## Requisitos previos

Haber trabajado con los datos de calabazas, ahora estamos suficientemente familiarizados con estos para entender que hay una categor√≠a binaria que podemos trabajar con `Color`.

Construyamos un modelo de regresi√≥n log√≠stica para predecirlo, dadas algunas variables, _qu√© color podr√≠a tener una calabaza dada_ (naranja üéÉ o blanca üëª).

> ¬øPorqu√© estamos hablando acerca de clasificaci√≥n binaria en un grupo de lecciones acerca de regresi√≥n? S√≥lo por conveniencia lig√º√≠stica, como la regresi√≥n log√≠stica es [realmente un m√©todo de clasificaci√≥n](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression), aunque de de base lineal. Aprende acerca de otras formas de clasificar los datos en el siguiente grupo de lecciones.

## Define la pregunta

Para nuestros prop√≥sitos, expresaremos esto como un binario: 'Orange' o 'Not Orange'. Tambi√©n hay una categor√≠a 'striped' en nuestro conjunto de datos pero hay menos instancias de √©stas, por lo que no las usaremos. √âsta desaparece una vez que removemos los valores nulos de nuestro conjunto de datos, de cualquier forma.

> üéÉ Dato gracioso, algunas veces llamamos 'fantasmas' a las calabazas blancas. No son muy f√°ciles de tallar, por lo que no son tan populares como las calabazas naranjas, ¬°pero se ven geniales!

## Acerca de la regresi√≥n log√≠stica

La regresi√≥n log√≠stica difiere de la regresi√≥n lineal, lo cual aprendiste previamentem en unas pocas cosas importantes.

### Clasificaci√≥n binaria

La regresi√≥n log√≠stica no ofrece las mismas caracter√≠sticas como la regresi√≥n lineal. Las primeras ofrecen una predicci√≥n acerca de categor√≠as binarias ("naranja o no naranja") mientras que la segunda es capaz de predecir valores continuos, por ejemplo dado el origen de una calabaza y el tiempo de cosecha, _cu√°nto incrementar√° su precio_.

![Modelo de clasificaci√≥n de calabazas](../images/pumpkin-classifier.png)
> Infograf√≠a de [Dasani Madipalli](https://twitter.com/dasani_decoded)
### Otras clasificaciones

Existen otros tipo de regresi√≥n log√≠stica, incluyendo la multinomial y ordinal:

- **Multinomial**, la cual implica tener m√°s de una categor√≠a - "Orange, White, and Striped".
- **Ordinal**, la cual implica categor√≠as ordenadas, √∫til si quisieramos ordenar nuestras resultados logicamente, como nuestras calabazas que est√°n ordenadas por un n√∫mero finito de tama√±os (mini,sm,med,lg,xl,xxl).

![Regresi√≥n multinomial vs ordinal](../images/multinomial-ordinal.png)
> Infograf√≠a de [Dasani Madipalli](https://twitter.com/dasani_decoded)

### Sigue siendo lineal

Aunqeu este tipo de regresi√≥n se trata de 'predicciones de categor√≠a', a√∫n funciona mejor cuando hay una relaci√≥n clara entre la variable dependiente (color) y las otras variables independientes (el resto del conjunto de datos, como el nombre de la ciudad y tama√±o). Es bueno tener una idea de si hay alguna linealidad dividiendo estas variables o no.

### Las variables NO tienen correlaci√≥n

¬øRecuerdas c√≥mo la regresi√≥n lineal funcion√≥ mejor con variables correlacionadas? La regresi√≥n log√≠stica es lo opuesto - las variables no se tienen que alinear. Eso funciona para estos datos los cuales tienen correlaciones algo d√©biles.

### Necesitas muchos datos limpios

La regresi√≥n log√≠stica te dar√° resultados m√°s precisos si usas m√°s datos; nuestro peque√±o conjunto de datos no es √≥ptimo para esta tarea, as√≠ que tenlo en mente.

‚úÖ piensa en los tipos de datos que se prestar√≠an bien para la regresi√≥n log√≠stica

## Ejercicio - arregla los datos

Primero, limpia los datos un poco, remueve los valores nulos y selecciona s√≥lo algunas de las columnas:

1. Agrega el siguiente c√≥digo:

    ```python
    from sklearn.preprocessing import LabelEncoder
    
    new_columns = ['Color','Origin','Item Size','Variety','City Name','Package']
    
    new_pumpkins = pumpkins.drop([c for c in pumpkins.columns if c not in new_columns], axis=1)
    
    new_pumpkins.dropna(inplace=True)
    
    new_pumpkins = new_pumpkins.apply(LabelEncoder().fit_transform)
    ```

    Siempre puedes echar un vistazo a tu nuevo dataframe:

    ```python
    new_pumpkins.info
    ```

### Visualizaci√≥n - cuadr√≠cula lado a lado

Por ahora has cargado el [starter notebook](../notebook.ipynb) con datos de calabazas una vez m√°s y los has limpiado para as√≠ preservar el conjunto de datos que contiene unas pocas variables, incluyendo `Color`. Visualizaremos el dataframe en el notebook usando una librer√≠a diferente: [Seaborn](https://seaborn.pydata.org/index.html), el cual es construido en Matplotlib que ya usamos anteriormente.

Seaborn ofrece algunas formas ingeniosas de visualizar tus datos. Por ejemplo, puedes comparar distribuciones de los datos para cada punto en una cuadr√≠cula lado a lado.

1. Crea dicha cuadr√≠cula instanciando `PairGrid`, usando nuestros datos de calabazas `new_pumpkins`, seguido de la llamada a `map()`:

    ```python
    import seaborn as sns
    
    g = sns.PairGrid(new_pumpkins)
    g.map(sns.scatterplot)
    ```

    ![Una cuadr√≠cula de datos visualizados](../images/grid.png)

    Al observar los datos lado a lado, puedes ver como los datos de Color se relacionan con las otras columnas.

    ‚úÖ Dada la cuadr√≠cula del gr√°fico de dispersi√≥n, ¬øcu√°les son algunas exploraciones interesantes que puedes visualizar?

### Usa un gr√°fico de enjambre

Dado que Color es una categor√≠a binaria (Naranja o no), se le llaman 'datos categ√≥ricos' y necesita 'un [enfoque m√°s especializado](https://seaborn.pydata.org/tutorial/categorical.html?highlight=bar) para visualizaci√≥n. Hay otras formas de visualizar las relaciones de esta categor√≠a con otras variables.

Puedes visualizar variables lado a lado con los gr√°ficos Seaborn.

1. Prueba un gr√°fico de 'enjambre' (swarm) para mostrar la distribuci√≥n de valores:

    ```python
    sns.swarmplot(x="Color", y="Item Size", data=new_pumpkins)
    ```

    ![Un enjambre de datos visualizados](../images/swarm.png)

### Gr√°fico de Viol√≠n

Un gr√°fico tipo 'viol√≠n' es √∫til ya que puedes visualizar f√°cilmente la forma en que los datos se distribuyen en las dos categor√≠as. Los g≈ïaficos de viol√≠n no funcionan muy bien con conjuntos de datos muy peque√±os ya que la distribuci√≥n se muestra m√°s 'suavemente'.

1. Como par√°metros `x=Color`, `kind="violin"` y llamada `catplot()`:

    ```python
    sns.catplot(x="Color", y="Item Size",
                kind="violin", data=new_pumpkins)
    ```

    ![un tipo de gr√°fico de viol√≠n](../images/violin.png)

    ‚úÖ Prueba a crear este gr√°fico, y otros gr√°ficos de Seaborn, usando otras variables.

Ahora que tenemos una idea de la relaci√≥n entre las categor√≠as binarias de color y el grupo mayor de tama√±os, exploremos la regresi√≥n log√≠stica para determinar el color probable de cierta calabaza.

> **üßÆ Mu√©strame las matem√°ticas**
>
> ¬øRecuerdas c√≥mo la regresi√≥n lineal suele ser us√≥ m√≠nimos cuadrados ordinarios para llegar al valor? La regresi√≥n log√≠stica se basa en el concepto de 'm√°xima probabilidad' usando [funciones sigmoides](https://wikipedia.org/wiki/Sigmoid_function). Una 'Funci√≥n Sigmoide' en una gr√°fico tiene la forma de una 'S'. Toma una valor lo asigna entre 0 y 1. Su curva tambi√©n es llamada 'curva log√≠stica'. Su f√≥rmula luce as√≠:
>
> ![Funci√≥n log√≠stica](../images/sigmoid.png)
>
> Donde el punto medio del sigmoide se encuentra en el punt 0 de las x, L es el valor m√°ximo de la curva, k es la pendiente de la curva. Si el resultado de la funci√≥n es m√°s de 0.5, la etiqueta en cuesti√≥n se le dar√° la clase '1' de la elecci√≥n binaria. Si no, ser√° clasificada como '0'.

## Construye tu modelo

Construir un modelo para encontrar estas clasificaciones binarias es sorprendentemente f√°cil en Scikit-learn.

1. Elige las variable que quieres usar en tu modelo de clasificaci√≥n y divide el modelo y los conjuntos de pruebas llamando `train_test_split()`:

    ```python
    from sklearn.model_selection import train_test_split
    
    Selected_features = ['Origin','Item Size','Variety','City Name','Package']
    
    X = new_pumpkins[Selected_features]
    y = new_pumpkins['Color']
    
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
    
    ```

1. Ahora puedes entrenar tu modelo, llamando `fit()` con tus datos entrenados, e imprimir su resultado:

    ```python
    from sklearn.model_selection import train_test_split
    from sklearn.metrics import accuracy_score, classification_report 
    from sklearn.linear_model import LogisticRegression
    
    model = LogisticRegression()
    model.fit(X_train, y_train)
    predictions = model.predict(X_test)
    
    print(classification_report(y_test, predictions))
    print('Predicted labels: ', predictions)
    print('Accuracy: ', accuracy_score(y_test, predictions))
    ```

    Echa un vistazo al marcador de tu modelo. No es tan malo, considerando tienes solo 1000 filas de datos:

    ```output
                       precision    recall  f1-score   support
    
               0       0.85      0.95      0.90       166
               1       0.38      0.15      0.22        33
    
        accuracy                           0.82       199
       macro avg       0.62      0.55      0.56       199
    weighted avg       0.77      0.82      0.78       199
    
    Predicted labels:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
     0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
     1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1
     0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1
     0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
     0 0 0 1 0 1 0 0 1 0 0 0 1 0]
    ```

## Mejor comprensi√≥n a trav√©s e una matriz de confusi√≥n

Mientras puedes obtener un reporte de [t√©rminos](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html?highlight=classification_report#sklearn.metrics.classification_report) del marcador imprimiendo los elementos de arriba, ser√°s capaz de entender tu modelo m√°s f√°cilmente usando una [matriz de confusi√≥n](https://scikit-learn.org/stable/modules/model_evaluation.html#confusion-matrix) para ayudarnos a entender c√≥mo se desempe√±a el modelo.

> üéì Una '[matriz de confusi√≥n](https://wikipedia.org/wiki/Confusion_matrix)' (o 'matriz de error') es una table que expresa los verdaderos vs los falsos positivos y negativos de tu modelo, para as√≠ medir la precisi√≥n de las predicciones.

1. Para usar m√©tricas de confusi√≥n, llama `confusion_matrix()`:

    ```python
    from sklearn.metrics import confusion_matrix
    confusion_matrix(y_test, predictions)
    ```

    Echa un vistazo a la matriz de confusi√≥n de tu modelo:

    ```output
    array([[162,   4],
           [ 33,   0]])
    ```

En Scikit-learn, las filas de las matriaces de confusi√≥n (eje 0) son etiquetas reales y las columnas (eje 1) son etiquetas previstas.

|       |   0   |   1   |
| :---: | :---: | :---: |
|   0   |  TN   |  FP   |
|   1   |  FN   |  TP   |

¬øQu√© pasa aqu√≠? Digamos que se le pidi√≥ a tu modelo clasificar las calabaas entre dos categor√≠as binarias, la categor√≠a 'orange' y la categor√≠a 'not-orange'.

- Si tu modelo predice una calabaza como no naranja y esta pertenece a la categor√≠a 'not-orange' en realidad la llamamos como un verdadero negativo, mostrado por el n√∫mero superior izquierdo.
- Si tu modelo precice una calabaza como naranja y esta pertenece a la categor√≠a 'not-orange' en realidad la llamamos como un falso negativo, mostrado por el n√∫mero inferior izquierdo.
- Si tu modelo predice una calabaza como no naranja y este pertenece a la categor√≠a 'orange' en realidad la llamamos como un falso positivo, mostrado por el n√∫mero superior derecho.
- Si tu modelo predice una calabaza como naranja y esta pertenece a la categor√≠a 'naranja' en realidad la llamamos como un verdadero positivo, mostrado por el n√∫mero inferior derecho.

Como habr√°s adivinado, es preferible tener un n√∫mero mayor de verdaderos positivos y verdaderos negativos, y un n√∫mero menor de falsos positivos y falsos negativos, lo cual implica que el modelo se desempe√±a mejor.

¬øC√≥mo se relaciona la matriz de confusi√≥n con precision (precisi√≥n) y recall (recuerdo)? Recuerda, el reporte de clasificaci√≥n impreso arriba mostr√≥ precisi√≥n (0.83) y recuerdo (0.98).

Precision = tp / (tp + fp) = 162 / (162 + 33) = 0.8307692307692308

Recall = tp / (tp + fn) = 162 / (162 + 4) = 0.9759036144578314

‚úÖ Q: De acuerdo a la matriz de confusi√≥n, ¬øc√≥mo lo hizo el modelo? A: No tan mal; existe un buen n√∫mero de verdaderos positivos pero tambi√©n varios falsos negativos.

Repasemos los t√©rmino que vimos anteriormente con la ayuda de la asignaci√≥n de la matriz de confusi√≥n de TP/TN y FP/FN:

üéì Precision: TP/(TP + FP) La fraci√≥n de instancias relevantes entre las instancias recuperadas (ejemplo, qu√© etiquetas fueron bien etiquetadas)

üéì Recall: TP/(TP + FN) La fracci√≥n de instancias relevantes que fueron recuperadas, bien etiquetadas o no

üéì f1-score: (2 * precision * recall)/(precision + recall) Un promedio ponderado de precisi√≥n y recuerdo, siendo lo mejor 1 y lo pero 0

üéì Soporte: El n√∫mero de ocurrencias de cada etiqueta recuperada

üéì Precisi√≥n: (TP + TN)/(TP + TN + FP + FN) El porcentaje de etiquetas previstas de forma precisa para la muestra.

üéì Promedio de macros: El c√°lculo de m√©tricas medias no ponderadas para cada etiqueta, no tomando en cuenta el desequilibrio de etiquetas.

üéì Promedio ponderado: El c√°lculo de las m√©tricas medias para cada etiqueta, tomando en cuenta el desequilibrio de etiquetas al ponderarlas po su soporte (el n√∫mero de instancias verdaderas para cada etiqueta).

‚úÖ ¬øPuedes pensar cu√°les m√©trcias debes observar si quieres que tu modelo para reducir el n√∫mero de falsos negativos?

## Visualiza la curva ROC de este modelo

Este no es un mal modelo; su precisi√≥n est√° en el rango de 80% ya que idealmente puedes usarlo para precedir el color de una calabaza dado un conjunto de variables.

Hagamos una visualizaci√≥n m√°s para ver el as√≠ llamado puntaje 'ROC':

```python
from sklearn.metrics import roc_curve, roc_auc_score

y_scores = model.predict_proba(X_test)
# calculate ROC curve
fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])
sns.lineplot([0, 1], [0, 1])
sns.lineplot(fpr, tpr)
```

Usando de nuevo Seaborn, grafica la [caracter√≠stica operativa de recepci√≥n](https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html?highlight=roc) del modelo o ROC. Las curvas ROC curves son usadas com√∫nmente para obtener una vista de la salida de un clasificador en t√©rminos de sus verdaderos positivos vs falsos positivos. "Las curvas ROC presentan t√≠picamente la tasa de verdaderos positivos en el eje Y, y la tasa falsos positivos en el eje X." As√≠, la inclinaci√≥n de la curvay el espeacio entre la l√≠nea del punto medio y la curva importan: quieres una curva que suba r√°pidamente y sobre la l√≠nea. En nuestro caso, hay falsos positivos para empezar, y luego la l√≠nea sube hac√≠a arriba y continua propiamente:

![ROC](../images/ROC.png)

Finalmente, usa la [API `roc_auc_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html?highlight=roc_auc#sklearn.metrics.roc_auc_score) de Scikit-learn para calcular el '√Årea bajo la curva' real (AUC):

```python
auc = roc_auc_score(y_test,y_scores[:,1])
print(auc)
```

El resultado es `0.6976998904709748`. Dado que la AUC var√≠a entre 0 y 1, quieres un puntaje grande, ya que un modelo que es 100% correcto en sus predicciones tendr√° un AUC de 1; en este caso el modelo es _bastante bueno_.

En futuras lecciones de clasificaci√≥n, aprender√°s c√≥mo iterar para mejorar los puntajes de tus modelos. Pero por ahora, ¬°felicitaciones!, ¬°Haz completado estas lecciones de regresi√≥n!

---

## üöÄDesaf√≠o

¬°Hay mucho m√°s para desempacar respecto a la regresi√≥n log√≠stica! Pero la mejor forma de aprender es experimentar. Encuentra un conjunto de datos que se preste para este tipo de an√°lisis y construye un modelo con √©l. ¬øQu√© aprendes? tipo: prueba [Kaggle](https://www.kaggle.com/search?q=logistic+regression+datasets) por conjuntos de datos interesantes.

## [Examen posterior a la lecci√≥n](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/16?loc=es)

## Revisi√≥n & autoestudio

Lee las primeras p√°ginas de este [art√≠culo de Stanford](https://web.stanford.edu/~jurafsky/slp3/5.pdf) de algunos usos pr√°cticos para la regresi√≥n log√≠stica. Piensa en las tareas que se ajustan mejor para uno u otro tipo de tareas de regresi√≥n que estudiamos hasta el momento. ¬øQue funcionar√≠a mejor?

## Asignaci√≥n

[Reintentando esta regresi√≥n](assignment.es.md)
