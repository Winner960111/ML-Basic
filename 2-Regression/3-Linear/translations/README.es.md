# Construye un modelo de regresi√≥n usando Scikit-learn: regresi√≥n de dos formas

![Infograf√≠a de regresi√≥n lineal vs polinomial](./images/linear-polynomial.png)
> Infograf√≠a de [Dasani Madipalli](https://twitter.com/dasani_decoded)

## [Examen previo a la lecci√≥n](https://white-water-09ec41f0f.azurestaticapps.net/quiz/13?loc=es)

> ### [¬°Esta lecci√≥n est√° disponible en R!](../solution/R/lesson_3-R.ipynb)

### Introducci√≥n

Hasta ahora has explorado qu√© es la regresi√≥n con datos obtenidos del conjunto de datos de los precios de las calabazas que usaremos en esta lecci√≥n. Tambi√©n los has visualizado usando Matplotlib.

Ahora est√°s listo para profundizar en la regresi√≥n para el aprendizaje autom√°tico. En esta lecci√≥n, aprender√°s m√°s acerca de dos tipos de regresi√≥n: _regresi√≥n b√°sica lineal_ y _regresi√≥n polinomial_, junto con algo de matem√°ticas fundamental a estas t√©cnicas.

> A lo largo de este plan de estudios, asumimos un conocimiento m√≠nimo de matem√°ticas, y buscamos hacerlo accesible para los estudiantes provenientes de otros campos, as√≠ que pon atenci√≥n a las notas, üßÆ llamados, diagramas, y otras herramientas de estudio para ayudar en la comprensi√≥n.

### Prerrequisitos

Ahora, debes estar familiarizado con la estructura de los datos de las calabazas que ya examinamos. Puedes encontrarlos precargados y pre-limpiados en el archivo _notebook.ipynb_ de esta lecci√≥n. En el archivo, el precio de la calabaza se muestra por fanega en un nuevo dataframe. Aseg√∫rate que puedas ejecutar estos notebooks en kernels en Visual Studio Code.

### Preparaci√≥n

Como recordatorio, est√°s cargando estos datos para hacer preguntas aceca de estos.

- ¬øCu√°ndo es el mejor momento para comprar calabazas?
- ¬øQu√© precio puedo esperar para el caso de calabazas miniatura?
- ¬øDeber√≠a comprarlas en cestos de media fanega o por caja de 1 1/9 de fanega?

Sigamos profundizando en estos datos.

En la lecci√≥n anterior, creaste un dataframe de Pandas y lo poblaste con parte del conjunto de datos original, estandarizando el precio de la fanega. Haci√©ndolo, s√≥lo fuiste capaz de reunir alrededor de 400 puntos de datos y s√≥lo para los meses de oto√±o.

Da un vistazo a los datos que fueron precargados en el notebook que acompa√±a a esta lecci√≥n. Los datos est√°n precargados con un gr√°fico de dispersi√≥n inicial para mostrar datos mensuales. Quiz√° podamos obtener un poco m√°s de detalle acerca de la naturaleza de los datos limpi√°ndolos m√°s.

## Un l√≠nea de regresi√≥n lineal

Como aprendiste en la lecci√≥n 1, el objetivo de un ejercicio de regresi√≥n lineal es ser capaz de graficar una l√≠nea para:

- **Mostrar la relaci√≥n de las variables**. Mostrar la relaci√≥n entre las variables
- **Realizar predicciones**. Hacer predicciones precisas en donde un nuevo punto de datos caer√≠a en relaci√≥n a esa l√≠nea.

Es t√≠pico de la **regresi√≥n de m√≠nimos cuadrados** el dibujar este tipo de l√≠nea. El t√©rmino 'm√≠nimos cuadrados' significa que todos los puntos de datos rodeando la l√≠nea de regresi√≥n se elevan al cuadrado y luego se suman. Idealmente, la suma final es tan peque√±a como sea posible, porque queremos un n√∫mero bajo de errores, o `m√≠nimos cuadrados`.

Lo hacemos as√≠ ya que queremos modelar una l√≠nea que tiene la menor distancia acumulada de todos nuestros puntos de datos. Tambi√©n elevamos al cuadrado los t√©rminos antes de sumarlos ya que nos interesa su magnitud en lugar de su direcci√≥n.

> **üßÆ Mu√©strame las matem√°ticas**
>
> Esta l√≠nea, llamada la _l√≠nea de mejor ajuste_ puede ser expresada por [una ecuaci√≥n](https://en.wikipedia.org/wiki/Simple_linear_regression):
>
> ```
> Y = a + bX
> ```
>
> `X` es la 'variable explicativa'. `Y` es la 'variable dependiente'. La pendiente de la l√≠nea es `b` y `a` es la intercepci√≥n en y, la cual se refiere a el valor de `Y` cuando `X = 0`.
>
>![Calcula la pendiente](../images/slope.png)
>
> Primero, calcula la pendiente `b`. Infograf√≠a de [Jen Looper](https://twitter.com/jenlooper)
>
> En otras palabras, y refiri√©ndose a nuestra pregunta original de los datos de las calabazas: "predice el precio de una calabaza por fanega por mes", `X` se referir√≠a al precio e `Y` a el mes de venta.
>
>![Completa la ecuaci√≥n](../images/calculation.png)
>
> Calcula el valor de Y. ¬°Si est√°s pagando alrededor de $4, debe ser Abril! Infograf√≠a de [Jen Looper](https://twitter.com/jenlooper)
>
> Las matem√°ticas que calculan la l√≠nea deben demostrar la pendiente de la l√≠nea, la cual tambi√©n depende de la intercepci√≥n, o d√≥nde `Y` se sit√∫a cuando `X = 0`.
>
> Puedes observar el m√©todo de c√°lculo para estos valores en el sitio web [las matem√°ticas son divertidas](https://www.mathsisfun.com/data/least-squares-regression.html). Tambi√©n visita esta [calculadora de m√≠nimos cuadrados](https://www.mathsisfun.com/data/least-squares-calculator.html) para ver c√≥mo los valores de los n√∫meros impactan la l√≠nea.

## Correlaci√≥n

Un t√©rmino m√°s a entender es el **coeficiente de correlaci√≥n** entre las variables dadas X e Y. Usando un gr√°fico de dispersi√≥n, puedes visualizar r√°pidamente este coeficiente. Un gr√°fico con puntos de datos dispersos en una l√≠nea ordenada tienen alta correlaci√≥n, pero un gr√°fico con puntos de datos dispersos por todas partes entre X e Y tienen baja correlaci√≥n.

Un buen modelo de regresi√≥n lineal ser√° aqu√©l que tenga un alto Coeficiente de Correlaci√≥n (m√°s cercano a 1 que a 0) usando el m√©tro de regresi√≥n de m√≠nimos cuadrados con una l√≠nea de regresi√≥n.

‚úÖ Ejecuta el notebook que acompa√±a esta lecci√≥n y mira el gr√°fico de Ciudad a Precio. ¬øLos datos asociados de Ciudad a Precio para las ventas de calabaza parecen tener correlaci√≥n alta o baja, de acuerdo a tu interpretaci√≥n visual del gr√°fico de dispersi√≥n?

## Prepara tus datos para la regresi√≥n

Ahora que tienes conocimiento de las matem√°ticas detr√°s de este ejercicio, crea un modelo de regresi√≥n para ver si puedes predecir cu√°l de los paquetes de calabazas tendr√° los mejores precios. Alguien comprando calabazas para una parcela de calabazas en d√≠as festivos quisiera esta informaci√≥n para ser capaz de optimizar sus compras de paquetes de calabazas para la parcela.

Ya que usar√°s Scikit-learn, no hay raz√≥n para hacer esto a mano (¬°aunque podr√≠as!). En el bloque principal de procesamientos de datos de tu notebook de lecci√≥n, agrega una biblioteca de Scikit-learn para convertir autom√°ticamente todos los datos de cadena a n√∫meros:

```python
from sklearn.preprocessing import LabelEncoder

new_pumpkins.iloc[:, 0:-1] = new_pumpkins.iloc[:, 0:-1].apply(LabelEncoder().fit_transform)
```

Si ahora miras el nuevo dataframe `new_pumpkins`, ves que todas las cadenas ahora son num√©ricas. ¬°Esto te dificulta el leer pero lo hace m√°s comprensible para Scikit-learn!
Ahora puedes tomar decisiones m√°s informadas (no s√≥lo basado en un gr√°fico de dispersi√≥n) acerca de los datos que mejor se ajustan a la regresi√≥n.

Intenta encontrar una buena correlaci√≥n entre dos puntos de tus datos para construir potencialmente un buen modelo predictivo. Como resultado, s√≥lo hay correlaci√≥n d√©bil entre la Ciudad y el Precio.

```python
print(new_pumpkins['City'].corr(new_pumpkins['Price']))
0.32363971816089226
```

Sin embargo, existe una correlaci√≥n un poco mejor entre el Paquete y su Precio. Esto tiene sentido, ¬øcierto? Normalmente, entre m√°s grande sea la caja producida, mayor ser√° el precio.

```python
print(new_pumpkins['Package'].corr(new_pumpkins['Price']))
0.6061712937226021
```

Una buena pregunta a realizar de estos datos, ser√≠a: '¬øQu√© precio puedo esperar de un paquete de calabazas dado?'

Construyamos este modelo de regresi√≥n

## Construyendo un modelo lineal

Antes de construir tu modelo, haz una limpieza m√°s a tus datos. Elimina cualquier dato nulo y verifica una vez c√≥mo lucen los datos.

```python
new_pumpkins.dropna(inplace=True)
new_pumpkins.info()
```

Luego, crea un dataframe nuevo de este conjunto m√≠nimo e impr√≠melo:

```python
new_columns = ['Package', 'Price']
lin_pumpkins = new_pumpkins.drop([c for c in new_pumpkins.columns if c not in new_columns], axis='columns')

lin_pumpkins
```

```output
	Package	Price
70	0	13.636364
71	0	16.363636
72	0	16.363636
73	0	15.454545
74	0	13.636364
...	...	...
1738	2	30.000000
1739	2	28.750000
1740	2	25.750000
1741	2	24.000000
1742	2	24.000000
415 rows √ó 2 columns
```

1. Ahora puedes asignar tus datos de coodenadas X e Y:

   ```python
   X = lin_pumpkins.values[:, :1]
   y = lin_pumpkins.values[:, 1:2]
   ```

‚úÖ ¬øQu√© est√° pasando aqu√≠? Est√°s usando [notaci√≥n slice de Python](https://stackoverflow.com/questions/509211/understanding-slice-notation/509295#509295) para crear arreglos y as√≠ poblar `X` e `Y`.

2. Lo siguiente es, iniciar las rutinas de construcci√≥n del modelo de regresi√≥n:

   ```python
   from sklearn.linear_model import LinearRegression
   from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
   from sklearn.model_selection import train_test_split

   X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
   lin_reg = LinearRegression()
   lin_reg.fit(X_train,y_train)

   pred = lin_reg.predict(X_test)

   accuracy_score = lin_reg.score(X_train,y_train)
   print('Model Accuracy: ', accuracy_score)
   ```

   Debido a que la correlaci√≥n nos es particularmente buena, el modelo producido no es terriblemente preciso.

   ```output
   Model Accuracy:  0.3315342327998987
   ```

3. Puedes visualziar la l√≠nea dibujada en el proceso:

   ```python
   plt.scatter(X_test, y_test,  color='black')
   plt.plot(X_test, pred, color='blue', linewidth=3)

   plt.xlabel('Package')
   plt.ylabel('Price')

   plt.show()
   ```

   ![Un gr√°fico de dispersi√≥n mostrando la relaci√≥n paquete a precio](../images/linear.png)

4. Prueba el modelo contra una variedad hipot√©tica:

   ```python
   lin_reg.predict( np.array([ [2.75] ]) )
   ```

   El precio devuelto para esta Variedad mitol√≥gica es:

   ```output
   array([[33.15655975]])
   ```

Ese n√∫mero hace sentido, si la l√≥gica de la regresi√≥n lineal es cierta.

üéÉ Felicidades, acabas de crear un modelo que puede ayudara predecir el precio de unas pocas variedades de calabazas. Tu parcela de calabazas de d√≠as festivos ser√°n hermosas. ¬°Pero probablemente puedes crear un mejor modelo!

## Regresi√≥n polinomial

Otro tipo de regresi√≥n lineal es la regresi√≥n polinomial. Mientras algunas veces existe una relaci√≥n lineal entre las variables - entre m√°s grande el volumen de la calabaza, mayor el precio - algunas veces estas relaciones no pueden ser graficadas como un plano o l√≠nea recta.

‚úÖ Aqu√≠ hay [m√°s ejemplos](https://online.stat.psu.edu/stat501/lesson/9/9.8) de los datos que podr√≠an usar regresi√≥n polinomial.

Da un vistazo m√°s a la relaci√≥n entre Variedad a Precio en la gr√°fica anterior. ¬øParece que el gr√°fico de dispersi√≥n deber√≠a ser analizado necesariamente por una l√≠nea recta? Quiz√° no. En este caso, puedes probar la regresi√≥n polinomial.

‚úÖ Los polinomios son expresiones matem√°ticas que pueden consistir en una o m√°s variables y coeficientes.

La regresi√≥n polinomial crea una l√≠nea curva para ajustar mejor los datos no lineales.

1. Recreemos un dataframe poblado con un segmento de los datos originales de las calabazas:

   ```python
   new_columns = ['Variety', 'Package', 'City', 'Month', 'Price']
   poly_pumpkins = new_pumpkins.drop([c for c in new_pumpkins.columns if c not in new_columns], axis='columns')

   poly_pumpkins
   ```

Una buena forma de visualizar las correlaciones entre los datos en los dataframes es mostrarlos en una gr√°fica 'coolwarm':

2. Usa el m√©todo `Background_gradient()` con `coolwarm` como valor de su argumento:

   ```python
   corr = poly_pumpkins.corr()
   corr.style.background_gradient(cmap='coolwarm')
   ```

   Este c√≥digo crea un mapa de calor:
   ![Un mapa de calor mostrando correlaci√≥n de datos](../images/heatmap.png)

Viendo esta gr√°fica, puedes visualizar la buena correlaci√≥n entre Paquete y Precio. As√≠ que deber√≠as ser capaz de crear un modelo algo mejor que el anterior.

### Crea un pipeline

Scikit-learn incluye una API √∫til para crear modelos de regresi√≥n polinomail - la [API](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html?highlight=pipeline#sklearn.pipeline.make_pipeline) `make_pipeline`. Se crea un 'pipeline' que es una cadena de estimadores. En este caso, el pipeline incluye caracter√≠sticas polinomiales, o predicciones que forman un camino no lineal.

1. Construye las columnas X e Y:

   ```python
   X=poly_pumpkins.iloc[:,3:4].values
   y=poly_pumpkins.iloc[:,4:5].values
   ```

2. Crea el pipeline llamando al m√©todo `make_pipeline()`:

   ```python
   from sklearn.preprocessing import PolynomialFeatures
   from sklearn.pipeline import make_pipeline

   pipeline = make_pipeline(PolynomialFeatures(4), LinearRegression())

   X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

   pipeline.fit(np.array(X_train), y_train)

   y_pred=pipeline.predict(X_test)
   ```

### Crea una secuencia

En este punto, necesitas crear un nuevo dataframe con datos _ordenados_ para que as√≠ el pipeline pueda crear una secuencia.

Agrega el siguiente c√≥digo:

   ```python
   df = pd.DataFrame({'x': X_test[:,0], 'y': y_pred[:,0]})
   df.sort_values(by='x',inplace = True)
   points = pd.DataFrame(df).to_numpy()

   plt.plot(points[:, 0], points[:, 1],color="blue", linewidth=3)
   plt.xlabel('Package')
   plt.ylabel('Price')
   plt.scatter(X,y, color="black")
   plt.show()
   ```

Creaste un nuevo dataframe llamando `pd.DataFrame`. Luego ordenaste los valores al llamar `sort_values()`. Finalmente creaste un gr√°fico polinomial:

![Un gr√°fico polinomial mostrando la relaci√≥n paquete a precio](../images/polynomial.png)

Puedes ver una l√≠nea curva que se ajusta mejor a tus datos.

Revisemos la precisi√≥n del modelo:

   ```python
   accuracy_score = pipeline.score(X_train,y_train)
   print('Model Accuracy: ', accuracy_score)
   ```

   ¬°Y voila!

   ```output
   Model Accuracy:  0.8537946517073784
   ```

¬°Es mejor! Intenta predecir un precio:

### Haz un predicci√≥n

¬øPodemos ingresar un nuevo valor y obtener una predicci√≥n?

Llama a `predict()` para hacer una predicci√≥n:

   ```python
   pipeline.predict( np.array([ [2.75] ]) )
   ```

   Se te presenta esta predicci√≥n:

   ```output
   array([[46.34509342]])
   ```

¬°Hace sentido, dado el gr√°fico! Y, si este es un mejor modelo que el anterior, viendo los mismos datos, ¬°necesitas presupuestar para estas calabazas m√°s caras!

üèÜ ¬°Bien hecho! Creaste dos modelos de regresi√≥n en una lecci√≥n. En la secci√≥n final de regresi√≥n, aprender√°s acerca de la regresi√≥n log√≠stica para determinar categor√≠as.

---

## üöÄDesaf√≠o

Prueba variables diferentes en este notebook para ver c√≥mo la correlaci√≥n corresponde a la precisi√≥n del modelo.

## [Examen posterior a la lecci√≥n](https://white-water-09ec41f0f.azurestaticapps.net/quiz/14?loc=es)

## Revisi√≥n y auto-estudio

En esta lecci√≥n aprendimos acerca de la regresi√≥n lineal. Existen otros tipos importantes de regresi√≥n. Lee acerca de las t√©cnicas paso a paso (Stepwise), cresta (Ridge), Lazo y red el√°stica (Lasso and Elasticnet). Un buen curso para estudiar para aprender m√°s es el [Curso de aprendizaje estad√≠stico de Stanford](https://online.stanford.edu/courses/sohs-ystatslearning-statistical-learning)

## Asignaci√≥n

[Construye un modelo](assignment.es.md)
