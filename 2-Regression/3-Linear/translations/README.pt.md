# Crie um modelo de regress√£o utilizando o Scikit-learning: regress√£o de dois modos

![Regress√£o linear vs polinomial infogr√°fica](./images/linear-polynomial.png)
> Infogr√°fico de [Dasani Madipalli](https://twitter.com/dasani_decoded)
## [Question√°rio pr√©-sele√ß√£o](https://white-water-09ec41f0f.azurestaticapps.net/quiz/13/)

> ### [Esta li√ß√£o est√° dispon√≠vel em R!](./solution/R/lesson_3-R.ipynb)
### Introdu√ß√£o

At√© agora, voc√™s exploraram o que √© a regress√£o com os dados de exemplo recolhidos a partir do conjunto de dados de pre√ßos da ab√≥bora que vamos usar ao longo desta li√ß√£o. Tamb√©m o visualizaram utilizando Matplotlib.

Agora est√° preparado para mergulhar mais profundamente na regress√£o para o ML. Nesta li√ß√£o, voc√™ vai aprender mais sobre dois tipos de regress√£o: _regress√£o linear b√°sica_ e _regress√£o polinomial_, juntamente com alguma da matem√°tica subjacente a estas t√©cnicas.

> Ao longo deste curr√≠culo, assumimos um conhecimento m√≠nimo de matem√°tica, e procuramos torn√°-lo acess√≠vel a estudantes provenientes de outras √°reas, por isso, procuremos notas, notas de üßÆ, diagramas e outras ferramentas de aprendizagem para ajudar na compreens√£o.

### Pr√©-requisitos

J√° devem conhecer a estrutura dos dados relativos √† ab√≥bora que estamos a analisar. Pode encontr√°-lo pr√©-carregado e previamente limpo no ficheiro _notebook.ipynb_ desta li√ß√£o. No ficheiro, o pre√ßo da ab√≥bora √© apresentado por defeito num novo dataframe.  Certifique-se de que pode executar estes blocos de notas em kernels no C√≥digo do Visual Studio.

### Prepara√ß√£o

Como lembrete, est√° a carregar estes dados para fazer perguntas sobre os mesmos.

- Quando √© o melhor momento para comprar ab√≥boras?
- Que pre√ßo posso esperar de um caso de ab√≥bora miniatura?
- Devo compr√°-los em cestos de meia-bushel ou pela caixa de bushel 1 1/9?
Vamos continuar a investigar estes dados.

Na li√ß√£o anterior, voc√™ criou um dataframe Pandas e o preencheu com parte do conjunto de dados original, padronizando os pre√ßos pelo bushel. Ao fazer isso, no entanto, voc√™ s√≥ conseguiu reunir cerca de 400 datapops e apenas nos meses de outono.

D√™ uma vista de olhos aos dados que pr√©-carreg√°mos no bloco de notas que acompanha esta li√ß√£o. Os dados s√£o pr√©-carregados e um gr√°fico de dispers√£o inicial √© desenhado para mostrar os dados do m√™s. Talvez possamos obter um pouco mais de detalhe sobre a natureza dos dados limpando-os mais.

## Uma linha de regress√£o linear

Como aprenderam na li√ß√£o 1, o objetivo de um exerc√≠cio de regress√£o linear √© conseguir desenhar uma linha para:

- **Mostrar rela√ß√µes de vari√°veis***. Mostrar a rela√ß√£o entre vari√°veis
- **Fa√ßa previs√µes**. Fa√ßa previs√µes precisas sobre onde um novo ponto de dados cairia em rela√ß√£o a essa linha.

√â t√≠pico de **Regress√£o dos Quadrados Menos** desenhar este tipo de linha. O termo 'menos quadrados' significa que todos os pontos de dados em torno da linha de regress√£o s√£o s√£o quadrados e depois adicionados. Idealmente, essa soma final √© o mais pequena poss√≠vel, porque queremos um n√∫mero reduzido de erros, ou `menos quadrados` .

Fazemo-lo porque queremos modelar uma linha que tenha a menor dist√¢ncia cumulativa de todos os nossos pontos de dados. N√≥s tamb√©m fazemos o quadrado dos termos antes de os adicionarmos, uma vez que estamos preocupados com a sua magnitude e n√£o com a sua dire√ß√£o.

> ** üßÆ Mostrar a matem√°tica**
>
> Esta linha, denominada a _linha de best fit_, pode ser expressa por [uma equa√ß√£o](https://en.wikipedia.org/wiki/Simple_linear_regression):
>
> ```
> Y = a + bX
> ```
>
> `X` √© a "vari√°vel explicativa". `Y` √© a 'vari√°vel dependente'. O declive da linha √© `b` e `a` √© a interce√ß√£o y, que se refere ao valor de `Y` quando `X = 0`.
>
>![calcule o declive](images/slope.png)
>
> Primeiro, calcular o declive `b`. Infogr√°fico por [Jen Looper](https://twitter.com/jenlooper)
>
> Por outras palavras, e referindo-se √† pergunta original dos nossos dados de ab√≥bora: "prever o pre√ßo de uma ab√≥bora por bordel por m√™s", `X` referiria-se ao pre√ßo e `Y` referiria-se ao m√™s de venda.
>
>![complete a equa√ß√£o](images/calculation.png)
>
> Calcular o valor de Y. Se voc√™ est√° pagando por volta de $4, deve ser abril! Infogr√°fico por [Jen Looper](https://twitter.com/jenlooper)
>
> A matem√°tica que calcula a linha deve demonstrar o declive da linha, que tamb√©m depende da interce√ß√£o, ou onde `Y` est√° situado quando `X = 0`.
>
> Pode observar o m√©todo de c√°lculo destes valores no Web site [Math is Fun](https://www.mathsisfun.com/data/least-squares-regression.html). Visite tamb√©m [esta calculadora de Menos quadrados](https://www.mathsisfun.com/data/least-squares-calculator.html) para ver como os valores dos n√∫meros t√™m impacto na linha.

## Correla√ß√£o

Mais um termo a compreender √© o **Coeficiente de Correla√ß√£o** entre as vari√°veis X e Y fornecidas. Usando um gr√°fico de dispers√£o, voc√™ pode visualizar rapidamente este coeficiente. Um desenho com pontos de dados dispersos numa linha reta tem uma correla√ß√£o elevada, mas um desenho com pontos de dados dispersos por todo o lado entre X e Y tem uma correla√ß√£o baixa.

Um bom modelo de regress√£o linear ser√° aquele que tem um Coeficiente de Correla√ß√£o elevado (mais perto de 1 que 0) utilizando o m√©todo de Regress√£o dos Menos Quadrados com uma linha de regress√£o.

‚úÖ Executar o bloco de notas que acompanha esta li√ß√£o e olhar para o gr√°fico de distribui√ß√£o City to Price. Os dados que associam a cidade ao pre√ßo das vendas de ab√≥bora parecem ter uma correla√ß√£o alta ou baixa, de acordo com a sua interpreta√ß√£o visual da distribui√ß√£o?


## Preparar os dados para regress√£o

Agora que t√™m uma compreens√£o da matem√°tica por detr√°s deste exerc√≠cio, criem um modelo de Regress√£o para ver se conseguem prever que pacote de ab√≥bora ter√° os melhores pre√ßos de ab√≥bora. Algu√©m que adquira ab√≥bora para uma corre√ß√£o de ab√≥bora de f√©rias poder√° querer que esta informa√ß√£o seja capaz de otimizar as suas compras de pacotes de ab√≥bora para a corre√ß√£o.

J√° que voc√™ vai usar o Scikit-learning, n√£o h√° raz√£o para fazer isso √† m√£o (embora voc√™ pudesse!). No bloco principal de processamento de dados do bloco de notas de li√ß√£o, adicione uma biblioteca do Scikit-learning para converter automaticamente todos os dados de cadeia em n√∫meros:

```python
from sklearn.preprocessing import LabelEncoder

new_pumpkins.iloc[:, 0:-1] = new_pumpkins.iloc[:, 0:-1].apply(LabelEncoder().fit_transform)
```

Se olharem para o dataframe new_bompkins, veem que todas as cadeias s√£o agora num√©ricas. Isto torna mais dif√≠cil para voc√™ ler, mas muito mais intelig√≠vel para o Scikit - aprender!
Agora, pode tomar decis√µes mais educadas (n√£o apenas com base no aparecimento de um gr√°fico de dispers√£o) sobre os dados que melhor se adequam √† regress√£o.

Tente encontrar uma boa correla√ß√£o entre dois pontos dos seus dados para criar, potencialmente, um bom modelo preditivo. Acontece que h√° apenas uma correla√ß√£o fraca entre a Cidade e o Pre√ßo:

```python
print(new_pumpkins['City'].corr(new_pumpkins['Price']))
0.32363971816089226
```

No entanto, h√° uma correla√ß√£o um pouco melhor entre o Pacote e o seu Pre√ßo. Isso faz sentido, certo? Normalmente, quanto maior for a caixa de produ√ß√£o, maior ser√° o pre√ßo.

```python
print(new_pumpkins['Package'].corr(new_pumpkins['Price']))
0.6061712937226021
```

Uma boa pergunta a fazer sobre estes dados ser√°: 'Que pre√ßo posso esperar de um determinado pacote de ab√≥bora?'

Vamos construir este modelo de regress√£o

## A criar um modelo linear

Antes de criar o seu modelo, fa√ßa mais uma arruma√ß√£o dos seus dados. Remova todos os dados nulos e verifique novamente como s√£o os dados.

```python
new_pumpkins.dropna(inplace=True)
new_pumpkins.info()
```

Em seguida, crie um novo dataframe a partir deste conjunto m√≠nimo e imprima-o:

```python
new_columns = ['Package', 'Price']
lin_pumpkins = new_pumpkins.drop([c for c in new_pumpkins.columns if c not in new_columns], axis='columns')

lin_pumpkins
```

```output
	Package	Price
70	0	13.636364
71	0	16.363636
72	0	16.363636
73	0	15.454545
74	0	13.636364
...	...	...
1738	2	30.000000
1739	2	28.750000
1740	2	25.750000
1741	2	24.000000
1742	2	24.000000
415 rows √ó 2 columns
```

1. Agora, pode atribuir os seus dados de coordenadas X e y:

   ```python
   X = lin_pumpkins.values[:, :1]
   y = lin_pumpkins.values[:, 1:2]
   ```
‚úÖ O que est√° acontecendo aqui? Est√° a utilizar [Python slice notation](https://stackoverflow.com/questions/509211/understanding-slice-notation/509295#509295) para criar matrizes para povoar ‚ÄòX‚Äô e ‚Äòy‚Äô.

2. Em seguida, inicie as rotinas de constru√ß√£o de modelos de regress√£o:

   ```python
   from sklearn.linear_model import LinearRegression
   from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
   from sklearn.model_selection import train_test_split

   X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
   lin_reg = LinearRegression()
   lin_reg.fit(X_train,y_train)

   pred = lin_reg.predict(X_test)

   accuracy_score = lin_reg.score(X_train,y_train)
   print('Model Accuracy: ', accuracy_score)
   ```

   Porque a correla√ß√£o n√£o √© particularmente boa, o modelo produzido n√£o √© terrivelmente preciso.

   ```output
   Model Accuracy:  0.3315342327998987
   ```

3. Pode visualizar a linha desenhada no processo:

   ```python
   plt.scatter(X_test, y_test,  color='black')
   plt.plot(X_test, pred, color='blue', linewidth=3)

   plt.xlabel('Package')
   plt.ylabel('Price')

   plt.show()
   ```
   ![Um gr√°fico de dispers√£o que mostra a rela√ß√£o pre√ßo/pacote](./images/linear.png)

4. Teste o modelo contra uma variedade hipot√©tica:

   ```python
   lin_reg.predict( np.array([ [2.75] ]) )
   ```
   
   O pre√ßo devolvido por esta Variedades mitol√≥gicas √©:

   ```output
   array([[33.15655975]])
   ```

Esse n√∫mero faz sentido, se a l√≥gica da linha de regress√£o se mantiver verdadeira.

üéÉ Parab√©ns, criaram um modelo que pode ajudar a prever o pre√ßo de algumas variedades de ab√≥bora. A sua mancha de ab√≥bora de f√©rias ser√° bonita. Mas √© prov√°vel que se possa criar um modelo melhor!
## Regress√£o polinomial

Outro tipo de regress√£o linear √© a regress√£o polinomial. Embora por vezes haja uma rela√ß√£o linear entre vari√°veis - quanto maior √© o volume da ab√≥bora, maior √© o pre√ßo - por vezes estas rela√ß√µes n√£o podem ser desenhadas como um plano ou uma linha reta.

‚úÖ Aqui est√£o [mais alguns exemplos](https://online.stat.psu.edu/stat501/lesson/9/9.8) de dados que podem utilizar regress√£o polinomial

Vejam outra vez a rela√ß√£o entre Varity e Price no desenho anterior. Parece que este gr√°fico de dispers√£o deve ser necessariamente analisado por uma linha reta? Talvez n√£o. Neste caso, pode-se tentar uma regress√£o polinomial.

‚úÖ Polinomiais s√£o express√µes matem√°ticas que podem ser compostas por uma ou mais vari√°veis e coeficientes

A regress√£o polinomial cria uma linha curvada para ajustar melhor os dados n√£o lineares.

1. Vamos recriar um dataframe povoado com um segmento dos dados originais da ab√≥bora:

   ```python
   new_columns = ['Variety', 'Package', 'City', 'Month', 'Price']
   poly_pumpkins = new_pumpkins.drop([c for c in new_pumpkins.columns if c not in new_columns], axis='columns')

   poly_pumpkins
   ```

Uma boa maneira de visualizar as correla√ß√µes entre os dados nos dataframes √© exibi-los em um gr√°fico 'colorido':

2. Utilize o m√©todo `Background_gradient()` com o valor de argumento `colarm`:

   ```python
   corr = poly_pumpkins.corr()
   corr.style.background_gradient(cmap='coolwarm')
   ```
   Este c√≥digo cria um mapa de calor:
![Um mapa de calor que mostra a correla√ß√£o de dados](./images/heatmap.png)

Olhando para este gr√°fico, pode visualizar a boa correla√ß√£o entre Pacote e Pre√ßo. Portanto, deveriam ser capazes de criar um modelo um pouco melhor do que o √∫ltimo.
### Criar um pipeline

Scikit-learning inclui uma API √∫til para a constru√ß√£o de modelos de regress√£o polinomial - o `make_pipeline` [API](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html?highlight=pipeline#sklearn.pipeline.make_pipeline). √â criado um "pipeline" que √© uma cadeia de estimadores. Neste caso, o pipeline inclui funcionalidades polinomiais ou previs√µes que formam um caminho n√£o linear.

1. Criar as colunas X e y:

   ```python
   X=poly_pumpkins.iloc[:,3:4].values
   y=poly_pumpkins.iloc[:,4:5].values
   ```

2. Crie o pipeline chamando o m√©todo "make_pipeline()":

   ```python
   from sklearn.preprocessing import PolynomialFeatures
   from sklearn.pipeline import make_pipeline

   pipeline = make_pipeline(PolynomialFeatures(4), LinearRegression())

   X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

   pipeline.fit(np.array(X_train), y_train)

   y_pred=pipeline.predict(X_test)
   ```

### Criar uma sequ√™ncia

Neste ponto, √© necess√°rio criar um novo dataframe com dados _sorted_ para que o pipeline possa criar uma sequ√™ncia.

Adicionar o seguinte c√≥digo:

   ```python
   df = pd.DataFrame({'x': X_test[:,0], 'y': y_pred[:,0]})
   df.sort_values(by='x',inplace = True)
   points = pd.DataFrame(df).to_numpy()

   plt.plot(points[:, 0], points[:, 1],color="blue", linewidth=3)
   plt.xlabel('Package')
   plt.ylabel('Price')
   plt.scatter(X,y, color="black")
   plt.show()
   ```

Criou um novo dataframe chamando `pd.DataFrame`. Em seguida, ordenou os valores chamando `sort_values()`. Finalmente criou um desenho polinomial:

![Um desenho polinomial que mostra a rela√ß√£o pacote/pre√ßo](./images/polynomial.png)

Pode ver uma linha curvada que se adapta melhor aos seus dados.

Vamos verificar a precis√£o do modelo:

   ```python
   accuracy_score = pipeline.score(X_train,y_train)
   print('Model Accuracy: ', accuracy_score)
   ```

   E voil√°!

   ```output
   Model Accuracy:  0.8537946517073784
   ```

Isso √© melhor! Tente prever um pre√ßo:

### Efetuar uma previs√£o

Podemos introduzir um novo valor e obter uma previs√£o?

Chame `predict()` para fazer uma previs√£o:
 
   ```python
   pipeline.predict( np.array([ [2.75] ]) )
   ```
   √â-lhe dada esta previs√£o:

   ```output
   array([[46.34509342]])
   ```

Faz sentido, dado o enredo! E, se este √© um modelo melhor do que o anterior, olhando para os mesmos dados, √© preciso or√ßar para estas abrigas mais caras!

üèÜ Parab√©ns! Criaram dois modelos de regress√£o numa li√ß√£o. Na √∫ltima sec√ß√£o sobre regress√£o, ir√° obter informa√ß√µes sobre regress√£o log√≠stica para determinar categorias.

‚Äî
## üöÄ desafio

Teste v√°rias vari√°veis diferentes neste bloco de notas para ver como a correla√ß√£o corresponde √† precis√£o do modelo.
##[Question√°rio p√≥s-palestra](https://white-water-09ec41f0f.azurestaticapps.net/quiz/14/)

## Revis√£o e Estudo Autom√°tico

Nesta li√ß√£o, aprendemos sobre a Regress√£o Linear. H√° outros tipos importantes de Regress√£o. Leia sobre as t√©cnicas Stepwise, Ridge, Lasso e Elasticnet. Um bom curso para estudar para aprender mais √© o [curso de Aprendizagem Estat√≠stica de Stanford](https://online.stanford.edu/courses/sohs-ystatslearning-statistical-learning)

## Atribui√ß√£o

[Criar um Modelo](assignment.md)
